# HNSW Post Review Notes

## Factual/Mathematical Corrections

### L44-45, L57: Greedy Walk Guarantee Overstated The claim that greedy walks
on the Delaunay graph always reach the true nearest neighbor is too strong.

**Current**: "We can see that we strictly decrease the dist(r', q) until we
reach a point where we can find no such r' such that dist(r', q) < dist(p', q),
which means p' _is_ the nearest neighbor of q."

**Issue**: The property "if q is not in p's Voronoi cell then there exists a
Delaunay neighbor closer to q" needs justification and is not generally true in
arbitrary metrics/spaces. Many walk procedures use additional geometric
predicates, not just an arbitrary improving step.

**Suggested fix**: Soften the claim: "On an exact Delaunay triangulation in
low-dimensional Euclidean space, local moves can be used to reach the Voronoi
cell containing q, but the details depend on the walking rule and geometry. In
high dimensions this structure becomes impractical anyway…"

---

### L59: Delaunay Complexity Numeric Example **Current**: "The graph would take
4 × 10^3000 bytes of space"

**Issue**: The O(n^⌈d/2⌉) bound is about the number of faces/simplices in worst
case; using it as "graph memory" is an oversimplification. The byte estimate
isn't anchored to edges-per-node or bytes-per-edge.

**Suggested fix**: Keep the qualitative point but present more cleanly:
"Worst-case Delaunay complexity grows superpolynomially with d (infeasible
beyond small d). Even storing a bounded-degree graph is why approximate methods
are used."

---

### L61-62: "Cap Neighbors" Framing **Current**: "this risks the greedy walk
stuck in local minima as there is no link diversity in the Delaunay graph"

**Issue**: The exact Delaunay graph is not bounded-degree in high d; the issue
is that once you approximate/sparsify, you may lose monotonic routing behavior.

**Suggested fix**: Explicitly say "after sparsification" to clarify.

---

### L69-75: Kleinberg Model Context Missing **Issue**: Kleinberg's theorem is
for a d-dimensional lattice/grid with a specific notion of distance and
    typically one long-range link per node. The prose applies it directly to an
    arbitrary point cloud.

**Suggested fix**: Add: "Kleinberg analyzed a grid; the takeaway is a heuristic
for how to distribute long-range edges by distance."

---

### L86-87: Ring Probability Derivation **Issue**: The derivation conflates
"distance exactly r" vs "in an annulus [r, r+dr]" and ignores normalization.
Fine for intuition but should be labeled as such.

**Suggested fix**: Say "density in an annulus scales like…" and mark it as
intuition.

---

### L122-125: Degree/Clustering Explanation **Current**: "Zoom in phase … nodes
generally will have high degrees; zoom out … low degrees."

**Issue**: In HNSW, degree is capped per layer (roughly constant M). Upper
layers are sparser because fewer nodes exist, not because nodes have low
degree. The "stuck" phenomenon is about local minima and insufficient long
links.

**Suggested fix**: Reframe: "Upper layers give long jumps because they're
sparse; bottom layer refines locally."

---

### L147-174: Level Distribution Parameterization **Issue**: You use a
geometric distribution, but standard HNSW uses an exponential tail. These are
related but m_L means different things in each formulation.

**Suggested fix**: Either: 1. Keep geometric version but explicitly say "we use
a geometric distribution with parameter…", or 2. Switch to common HNSW
parameterization L = ⌊-m_L ln U⌋ and define m_L the way the paper does.

Also: If U=0, ln(U) is -∞. Clamp: `U = max(U, eps)`.

---

### L177-182: Query-Time Complexity Argument **Current**: "Search on layer l
would always terminate before encountering a node present in l+1"

**Issue**: This is false—nodes from l+1 also exist in l, and the layer-l search
can visit them. The derivation "expected steps per layer = m_L independent of
n" is not a valid proof.

**Suggested fix**: Don't try to prove O(log n) this way. Safer wording:
"Empirically HNSW achieves logarithmic-like scaling on many datasets; the
original paper motivates this via the hierarchical construction and bounded
out-degree."

---

## Clarity/Understandability Improvements

### L14-16: Problem Setup **Issue**: Jumps between "nearest neighbor" and
"bunch of vectors" without naming dataset/query and distance metric.

**Suggested fix**: Define X = {x_i}, query q, distance dist(·,·), and goal
argmin_i dist(x_i, q).

---

### L32: Voronoi → Delaunay Explanation **Current**: "each Voronoi cell as a
node in graph"

**Issue**: It's more common to say "each site/point is a node; connect two
sites if their Voronoi cells share a boundary."

**Suggested fix**: "Make a graph on points where edges connect points with
adjacent Voronoi cells; that graph is the Delaunay graph."

---

### L44-45: Greedy Walk Paragraph **Issue**: Long run-on paragraph with many
pronoun references ("this", "the").

**Suggested fix**: Split into 3-4 sentences with a concrete invariant: "At each
step we move to a neighbor that reduces dist(·,q). Because distance strictly
decreases and the graph is finite, the walk terminates."

---

### L57: "Any Closer" vs "Closest" **Issue**: Readers may ask if choosing "any
closer" preserves correctness.

**Suggested fix**: Explicitly state: "This is a heuristic; choosing the closest
often reduces hops but costs extra distance computations."

---

### L86-107: NSW/Kleinberg Derivation **Suggested fix**: Add headings like
"Intuition" vs "Sketch of the calculation" to signal approximations.

---

### L175-176: Neighbor Selection Heuristic **Current**: "We add a neighbor iff
the neighbor is closer to us than any other neighbors"

**Issue**: Ambiguous wording.

**Suggested fix**: More precise: "Sort candidates by distance to the new node;
keep a candidate if it is not too close to any already selected neighbor
(distance(candidate, selected) < distance(candidate, new))."

---

### L211-217: Parameter List **Issue**: `num_words` appears in code but not
explained.

---

## Code Issues

### L364-365, L391-392: Parameter Name Mismatches
- Code references `self.params.max_neighbors_layer0` (doesn't exist in struct)
- Uses `max_nodes_layer0` / `max_nodes_per_layer` (different names)

**Fix**: Unify names consistently.

---

### L307-311: log(0) Edge Case If `urandom = 0`, then `ln(urandom)` is -∞.

**Fix**: Clamp: `const urandom = @max(random.float(f64), 1e-10);`

---

### L356: Index Assumption Writes edges into `self.nodes.items[idx]` where
`idx` is the external node index passed to `insert`.

**Issue**: Only works if idx always equals the position in self.nodes (strictly
increasing order with no gaps).

**Fix**: After append, set `const node_id: NodeIdx =
@intCast(self.nodes.items.len - 1);` and use node_id for graph storage.

---

### L371-372: Memory Leak `curr_entry_points = current_nearest;` overwrites the
previous list without deinit/free.

**Fix**: Either mention "omitting frees for brevity" or show proper deinit.

---

### L437-439: topK Returns Potentially Wrong Results
`shrinkRetainingCapacity(k)` just truncates; doesn't ensure you're taking the k
closest unless searchLayer guarantees sorted-by-distance order.

**Fix**: Either:
- Return ef_search candidates and partial-sort by distance, take top-k, or
- Ensure searchLayer returns sorted by increasing distance and ef_search >= k
